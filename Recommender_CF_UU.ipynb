{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and format json data\n",
    "Importing playlists from jsons and formatting them into ratings data frame. (Get data from https://owncloud.tuwien.ac.at/index.php/s/A8Wx2TpFr0WznZh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# load data\n",
    "train = json.load(open('data/train.json', encoding = \"utf8\"))\n",
    "\n",
    "dev = json.load(open('data/dev.json', encoding = \"utf8\"))\n",
    "dev_trun = json.load(open('data/dev_trun.json', encoding=\"utf8\"))\n",
    "\n",
    "test = json.load(open('data/test.json', encoding = \"utf8\"))\n",
    "test_trun = json.load(open('data/test_trun.json', encoding = \"utf8\"))\n",
    "\n",
    "# create ratings df with training + dev for validation (equivalent to 'ratings_train' data frame in Assignment 4.1)\n",
    "rating_list = []\n",
    "only_dev_list = []\n",
    "\n",
    "seen = set()\n",
    "track_list = []\n",
    "track_pnames_dev_dict=dict()\n",
    "\n",
    "dev_playlist_pids = []\n",
    "\n",
    "for playlist in train['playlists'][:1000]:\n",
    "    if len(playlist['tracks']) == 0:\n",
    "        continue\n",
    "    for track in playlist['tracks']:\n",
    "        rating_list.append([playlist['pid'], playlist['name'], track['track_uri'], 1.0])\n",
    "        if track['track_uri'] not in seen:\n",
    "            seen.add(track['track_uri'])\n",
    "            track_pnames_dev_dict[track['track_uri']] =  [playlist['name']]\n",
    "            track_list.append([track['track_uri'], track['track_name'], track['artist_uri'], track['artist_name'], track['album_uri'], track['album_name'], track['duration_ms']])\n",
    "        else:\n",
    "            l = track_pnames_dev_dict[track['track_uri']]\n",
    "            l.append(playlist['name'])\n",
    "            track_pnames_dev_dict[track['track_uri']] = l\n",
    "            \n",
    "for playlist in dev_trun['playlists']:\n",
    "    if len(playlist['tracks']) == 0:\n",
    "        continue\n",
    "    dev_playlist_pids.append(playlist['pid'])\n",
    "    for track in playlist['tracks']:\n",
    "        rating_list.append([playlist['pid'], playlist['name'], track['track_uri'], 1.0])\n",
    "        only_dev_list.append([playlist['pid'], playlist['name'], track['track_uri'], 1.0])\n",
    "        if track['track_uri'] not in seen:\n",
    "            seen.add(track['track_uri'])\n",
    "            track_pnames_dev_dict[track['track_uri']] =  [playlist['name']]\n",
    "            track_list.append([track['track_uri'], track['track_name'], track['artist_uri'], track['artist_name'], track['album_uri'], track['album_name'], track['duration_ms']])\n",
    "        else:\n",
    "            l = track_pnames_dev_dict[track['track_uri']]\n",
    "            l.append(playlist['name'])\n",
    "            track_pnames_dev_dict[track['track_uri']] = l\n",
    "            \n",
    "ratings_train_dev = pd.DataFrame(rating_list, columns = ['pid', 'name', 'track_uri', 'rating'])\n",
    "ratings_only_dev = pd.DataFrame(only_dev_list, columns = ['pid', 'name', 'track_uri', 'rating'])\n",
    "tracks_dev = pd.DataFrame(track_list, columns = ['track_uri', 'track_name', 'artist_uri', 'artist_name', 'album_uri', 'album_name', 'duration_ms'])\n",
    "\n",
    "dev_playlist_pids = list(set(dev_playlist_pids))\n",
    "#print(len(dev_playlist_pids))\n",
    "\n",
    "# create ratings df for testing\n",
    "rating_list = []\n",
    "only_test_list = []\n",
    "\n",
    "seen = set()\n",
    "track_list = []\n",
    "track_pnames_test_dict=dict()\n",
    "\n",
    "test_playlist_pids = []\n",
    "\n",
    "for playlist in train['playlists'][:1000]:\n",
    "    if len(playlist['tracks']) == 0:\n",
    "        continue\n",
    "    for track in playlist['tracks']:\n",
    "        rating_list.append([playlist['pid'], playlist['name'], track['track_uri'], 1.0])\n",
    "        if track['track_uri'] not in seen:\n",
    "            seen.add(track['track_uri'])\n",
    "            track_pnames_test_dict[track['track_uri']] =  [playlist['name']]\n",
    "            track_list.append([track['track_uri'], track['track_name'], track['artist_uri'], track['artist_name'], track['album_uri'], track['album_name'], track['duration_ms']])\n",
    "        else:\n",
    "            l = track_pnames_test_dict[track['track_uri']]\n",
    "            l.append(playlist['name'])\n",
    "            track_pnames_test_dict[track['track_uri']] = l\n",
    "            \n",
    "for playlist in test_trun['playlists']:\n",
    "    if len(playlist['tracks']) == 0:\n",
    "        continue\n",
    "    test_playlist_pids.append(playlist['pid'])\n",
    "    for track in playlist['tracks']:\n",
    "        rating_list.append([playlist['pid'], playlist['name'], track['track_uri'], 1.0])\n",
    "        only_test_list.append([playlist['pid'], playlist['name'], track['track_uri'], 1.0])\n",
    "        if track['track_uri'] not in seen:\n",
    "            seen.add(track['track_uri'])\n",
    "            track_pnames_test_dict[track['track_uri']] =  [playlist['name']]\n",
    "            track_list.append([track['track_uri'], track['track_name'], track['artist_uri'], track['artist_name'], track['album_uri'], track['album_name'], track['duration_ms']])\n",
    "        else:\n",
    "            l = track_pnames_test_dict[track['track_uri']]\n",
    "            l.append(playlist['name'])\n",
    "            track_pnames_test_dict[track['track_uri']] = l\n",
    "            \n",
    "ratings_train_test = pd.DataFrame(rating_list, columns = ['pid', 'name', 'track_uri', 'rating'])\n",
    "ratings_only_test = pd.DataFrame(only_test_list, columns = ['pid', 'name', 'track_uri', 'rating'])\n",
    "tracks_test = pd.DataFrame(track_list, columns = ['track_uri', 'track_name', 'artist_uri', 'artist_name', 'album_uri', 'album_name', 'duration_ms'])\n",
    "\n",
    "test_playlist_pids = list(set(test_playlist_pids))\n",
    "#print(len(test_playlist_pids))\n",
    "\n",
    "# holdouts ('topN' equivalent)\n",
    "dev_holdouts = {playlist['pid']:playlist['num_holdouts'] for playlist in dev['playlists']}\n",
    "test_holdouts = {playlist['pid']:playlist['num_holdouts'] for playlist in test['playlists']}\n",
    "\n",
    "#ratings_train_dev.head()\n",
    "#tracks_dev.head()\n",
    "#track_pnames_dev_dict\n",
    "\n",
    "print(len(ratings_train_test.pid.unique()))\n",
    "\n",
    "# not sure if train and dev need to be combined.. train alone doesn't miss any tracks, \n",
    "# so we cannot test the model on it. Combining it with def, we can make predictions on\n",
    "# missing tracks in dev playlists. EDIT: I think combining is right. Also combining train + test. \n",
    "# Otherwise, train isn't part of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and build recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from Recommender_CB import ContentBasedRecommender\n",
    "from Recommender_CF_UU import UUCFRecommender\n",
    "#from Recommender_MF import MFRecommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UU-CB\n",
    "uucf_1 = UUCFRecommender(k = 100)\n",
    "%time uucf_1.build_model(ratings_train_test)\n",
    "print(\"Finished building model for k=50\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Content-based \n",
    "#cbr_extended = ContentBasedRecommender('extended')\n",
    "#%time cbr_extended.build_model(ratings_only_dev, tracks_dev)\n",
    "#%time cbr_extended.build_model(ratings_train_dev, tracks_dev)\n",
    "\n",
    "#cbr_general = ContentBasedRecommender('general')\n",
    "#%time cbr_general.build_model(ratings_only_dev, tracks_dev)\n",
    "#%time cbr_extended.build_model(ratings_train_dev, tracks_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample\n",
    "\n",
    "#%time cbr_extended_recs = cbr_extended.recommend(498917, topN = dev_holdouts.get(498917))\n",
    "#print(cbr_extended_recs)\n",
    "\n",
    "#%time cbr_general_recs = cbr_general.recommend(498917, topN = dev_holdouts.get(498917))\n",
    "#print(cbr_general_recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning\n",
    "Parameters are tuned through evaluating performance of different parameter settings on the train+dev (?) set. Those settings will be used for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load ground truth\n",
    "\n",
    "import metrics\n",
    "infile = 'data/dev_gt.txt'\n",
    "split_pits = None\n",
    "with open(infile, 'rt') as f_i:\n",
    "    split_pits = [z.strip(' ()') for z in f_i.read().strip().split('\\n')]\n",
    "\n",
    "target_sets = dict()\n",
    "if split_pits:\n",
    "    for tup in split_pits:\n",
    "        k = tup.split(', ')[0]\n",
    "        v = list()\n",
    "        for z in tup.split(', ')[1:]:\n",
    "            v.append(z.strip(' '))\n",
    "        target_sets[k] = v\n",
    "        \n",
    "#target_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UU-CF\n",
    "\n",
    "import csv\n",
    "\n",
    "# recommend for var#to_evaluate playlists in test set\n",
    "\n",
    "file_output = []\n",
    "R_precisions = {}\n",
    "NDCGs = {}\n",
    "R_list = []\n",
    "NDCG_list = []\n",
    "\n",
    "#debug\n",
    "#print(\"yo\", flush=True)\n",
    "#uucf_1_recs = uucf_1.recommend(498917, topN = dev_holdouts.get(498917))\n",
    "#print(uucf_1_recs, flush=True)\n",
    "#print(\"I was here\", flush=True)\n",
    "\n",
    "print(\"Parameter settings #1 (k=100) and using 1100 playlists------------------\", flush=True)\n",
    "for pid in dev_playlist_pids:  \n",
    "    uucf_1_recs = uucf_1.recommend(pid, topN = dev_holdouts.get(pid))\n",
    "    R_precisions[pid] = metrics.r_precision(target_sets.get(str(pid)), uucf_1_recs, dev_holdouts.get(pid))\n",
    "    NDCGs[pid] = metrics.ndcg(target_sets.get(str(pid)), uucf_1_recs, dev_holdouts.get(pid))\n",
    "    #--- for average calc\n",
    "    R_list.append(metrics.r_precision(target_sets.get(str(pid)), uucf_1_recs, dev_holdouts.get(pid)))\n",
    "    NDCG_list.append(metrics.ndcg(target_sets.get(str(pid)), uucf_1_recs, dev_holdouts.get(pid)))\n",
    "    #---\n",
    "    to_append_to_file = [pid]\n",
    "    to_append_to_file.extend(uucf_1_recs)\n",
    "    print(\"Result:\")\n",
    "    file_output.append(to_append_to_file)\n",
    "    print('pid:', pid, 'r_prec:', R_precisions[pid], 'NDCG:', NDCGs[pid], flush=True)\n",
    "\n",
    "print('Average r_prec: ', sum(R_list) / float(len(R_list)), ' ', 'Average NDCG: ', sum(NDCG_list) / float(len(NDCG_list)), flush=True)\n",
    "#print(file_output, flush=True)\n",
    "\n",
    "with open('data/test_cf_uu_k_5_recommendations.csv', 'w') as output:\n",
    "    wr = csv.writer(output)\n",
    "    wr.writerows(file_output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing one recommendation\n",
    "\n",
    "#target_set = target_sets.get('498917')\n",
    "\n",
    "#k = dev_holdouts.get(498917)\n",
    "\n",
    "#TODO: Evaluate results:\n",
    "# CB Accuracy\n",
    "#print(metrics.r_precision(target_set, cbr_extended_recs, k))\n",
    "#print(metrics.r_precision(target_set, cbr_general_recs, k))\n",
    "#CB NDCG\n",
    "#print(metrics.ndcg(target_set, cbr_extended_recs, k))\n",
    "#print(metrics.ndcg(target_set, cbr_general_recs, k))\n",
    "\n",
    "\n",
    "#TODO: Parameter tuning\n",
    "## Content-based \n",
    "#cbr = ContentBasedRecommender('extended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running extended and general CB recommendation on a subset of dev playlists and taking the one with the better average\n",
    "\n",
    "# extended\n",
    "#file_output = []\n",
    "#R_precisions = {}\n",
    "#NDCGs = {}\n",
    "#R_list = []\n",
    "#NDCG_list = []\n",
    "\n",
    "#print(\"Extended Dev------------------------\", flush=True)\n",
    "#for pid in dev_playlist_pids[1:5]:  \n",
    "#    %time cbr_extended_recs = cbr_extended.recommend(pid, topN = dev_holdouts.get(pid))\n",
    "#    R_precisions[pid] = metrics.r_precision(target_sets.get(str(pid)), cbr_extended_recs, k)\n",
    "#    NDCGs[pid] = metrics.ndcg(target_sets.get(str(pid)), cbr_extended_recs, k)\n",
    "#    #--- for average calc\n",
    "#    R_list.append(metrics.r_precision(target_sets.get(str(pid)), cbr_extended_recs, k))\n",
    "#    NDCG_list.append(metrics.ndcg(target_sets.get(str(pid)), cbr_extended_recs, k))\n",
    "#    #---\n",
    "#    to_append_to_file = [pid]\n",
    "#    to_append_to_file.extend([cbr_extended_recs])\n",
    "#    file_output.append(to_append_to_file)\n",
    "#    print('pid: ', pid, 'r_prec: ', R_precisions[pid], ' ', 'NDCG: ', NDCGs[pid], flush=True)\n",
    "\n",
    "#print('Average r_prec: ', sum(R_list) / float(len(R_list)), ' ', 'Average NDCG: ', sum(NDCG_list) / float(len(NDCG_list)), flush=True)\n",
    "#print(file_output, flush=True)\n",
    "\n",
    "\n",
    "# general\n",
    "#file_output = []\n",
    "#R_precisions = {}\n",
    "#NDCGs = {}\n",
    "#R_list = []\n",
    "#NDCG_list = []\n",
    "\n",
    "#print(\"General Dev------------------------\", flush=True)\n",
    "#for pid in dev_playlist_pids[:5]:  \n",
    "#    %time cbr_general_recs = cbr_general.recommend(pid, topN = dev_holdouts.get(pid))\n",
    "#    R_precisions[pid] = metrics.r_precision(target_sets.get(str(pid)), cbr_general_recs, k)\n",
    "#    NDCGs[pid] = metrics.ndcg(target_sets.get(str(pid)), cbr_general_recs, k)\n",
    "#    #--- for average calc\n",
    "#    R_list.append(metrics.r_precision(target_sets.get(str(pid)), cbr_general_recs, k))\n",
    "#    NDCG_list.append(metrics.ndcg(target_sets.get(str(pid)), cbr_general_recs, k))\n",
    "#    #---\n",
    "#    to_append_to_file = [pid]\n",
    "#    to_append_to_file.extend([cbr_general_recs])\n",
    "#    file_output.append(to_append_to_file)\n",
    "#    print('pid: ', pid, 'r_prec: ', R_precisions[pid], ' ', 'NDCG: ', NDCGs[pid], flush=True)\n",
    "\n",
    "#print('Average r_prec: ', sum(R_list) / float(len(R_list)), ' ', 'Average NDCG: ', sum(NDCG_list) / float(len(NDCG_list)), flush=True)  \n",
    "#print(file_output, flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on test set and writing to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load ground truth\n",
    "\n",
    "import metrics\n",
    "infile = 'data/test_gt.txt'\n",
    "split_pits = None\n",
    "with open(infile, 'rt') as f_i:\n",
    "    split_pits = [z.strip(' ()') for z in f_i.read().strip().split('\\n')]\n",
    "\n",
    "target_sets = dict()\n",
    "if split_pits:\n",
    "    for tup in split_pits:\n",
    "        k = tup.split(', ')[0]\n",
    "        v = list()\n",
    "        for z in tup.split(', ')[1:]:\n",
    "            v.append(z.strip(' '))\n",
    "        target_sets[k] = v\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UU-CF\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "# recommend for var#to_evaluate playlists in test set\n",
    "\n",
    "file_output = []\n",
    "R_precisions = {}\n",
    "NDCGs = {}\n",
    "R_list = []\n",
    "NDCG_list = []\n",
    "\n",
    "#debug\n",
    "#print(\"yo\", flush=True)\n",
    "#uucf_1_recs = uucf_1.recommend(498917, topN = dev_holdouts.get(498917))\n",
    "#print(uucf_1_recs, flush=True)\n",
    "#print(\"I was here\", flush=True)\n",
    "\n",
    "print(\"Parameter settings #1 (k=100) and using 1100 playlists------------------\", flush=True)\n",
    "for pid in test_playlist_pids:  \n",
    "    uucf_1_recs = uucf_1.recommend(pid, topN = test_holdouts.get(pid))\n",
    "    R_precisions[pid] = metrics.r_precision(target_sets.get(str(pid)), uucf_1_recs, test_holdouts.get(pid))\n",
    "    NDCGs[pid] = metrics.ndcg(target_sets.get(str(pid)), uucf_1_recs, test_holdouts.get(pid))\n",
    "    #--- for average calc\n",
    "    R_list.append(metrics.r_precision(target_sets.get(str(pid)), uucf_1_recs, test_holdouts.get(pid)))\n",
    "    NDCG_list.append(metrics.ndcg(target_sets.get(str(pid)), uucf_1_recs, test_holdouts.get(pid)))\n",
    "    #---\n",
    "    to_append_to_file = [pid]\n",
    "    to_append_to_file.extend(uucf_1_recs)\n",
    "    file_output.append(to_append_to_file)\n",
    "    print('pid:', pid, 'r_prec:', R_precisions[pid], 'NDCG:', NDCGs[pid], flush=True)\n",
    "\n",
    "print('Average r_prec: ', sum(R_list) / float(len([i for i, e in enumerate(R_list) if e != 0])), ' ', 'Average NDCG: ', sum(NDCG_list) / float(len([i for i, e in enumerate(NDCG_list) if e != 0])), flush=True)\n",
    "#print(file_output, flush=True)\n",
    "\n",
    "with open('data/test_cf_k100_samples1100_recommendations.csv', 'w') as output:\n",
    "    wr = csv.writer(output, lineterminator='\\n')\n",
    "    wr.writerows(file_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
